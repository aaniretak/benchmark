{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Katerina\\Anaconda3\\envs\\benchmarkapp\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf # Tensorflow 2.3\n",
    "import tensorflow_hub as hub # Tensorflow-hub 0.12\n",
    "import PIL.Image as Image # Pillow \n",
    "import numpy as np # Numpy\n",
    "from tqdm import tqdm # progress bar package\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "from time import process_time\n",
    "from memory_profiler import memory_usage\n",
    "from ipynb.fs.full.utilities import *\n",
    "import tempfile\n",
    "import tracemalloc\n",
    "\n",
    "#se sxesi me ton xrono: default_timer == perf_counter\n",
    "#perf_counter:does include time elapsed during sleep\n",
    "#process_time(): does NOT include time elapsed during sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "task = int(input(\"Choose a problem domain by typing the corresponding number: \\n1.Image\\n2.Text\\n3.Video\\n4.Audio\"))\n",
    "if(task == 1):\n",
    "    task = int(input(\"Choose a task by typing the corresponding number:\\n1.Image Classification\\n2.Image Segmentation\\n3.Pose Estimation\"))\n",
    "    if(task == 1):\n",
    "        task = int(input(\"Choose a model by typing the corresponding number:\\n1.MobileNet V2\\n2.ResNet50 V1\\n3.Inception V3\\n4.NASNet-A large\\n5.EfficientNet V2 M\"))\n",
    "\n",
    "dataset = input('Absolute path to the dataset')\n",
    "values = input('Absolute path to the text file of the groundtruth')\n",
    "'''\n",
    "\n",
    "batch = int(input(\"Insert batch size\"))\n",
    "if batch == 1:\n",
    "    batch = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Groundtruth\n",
    "val_groundtruth = load_values('Datasets/ImageNet/val.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\", output_shape=[1001])\n",
    "])\n",
    "model.build([batch,224,224,3]) # Batch input shape\n",
    "image_shape = (224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 14MB\n",
      "Peak memory usage is: 592070 KiB \n",
      "Top-1 accuracy for 1000 images is: 70.1 %\n",
      "Top-5 accuracy for 1000 images is: 90.2 %\n",
      "Latency is: 0.54 s\n",
      "Throughput is: 1.84 samples/sec\n"
     ]
    }
   ],
   "source": [
    "# Inference and metrics\n",
    "\n",
    "t1 = 0 # Variable for correct predictions\n",
    "t5 = 0 # Variable for top-5 correct predictions\n",
    "\n",
    "imagenum = 0\n",
    "duration = 0\n",
    "data = np.zeros((1000 , 224, 224, 3))\n",
    "\n",
    "for file in os.listdir('Datasets/ImageNet')[:1000]:\n",
    "    image = Image.open(os.path.join('Datasets/ImageNet', file), 'r')\n",
    "    data[imagenum,:] = preprocessing(image, image_shape)[0] # Preprocessing\n",
    "    imagenum += 1\n",
    "\n",
    "tracemalloc.start()\n",
    "start = process_time()    \n",
    "prediction = model.predict(data,batch_size = batch)\n",
    "duration += (process_time()-start)\n",
    "\n",
    "for i in range(imagenum):\n",
    "    if((val_groundtruth[i]+1) in np.argpartition(prediction[i], -5)[-5:]): # argpartition σε Ο(n) για τα top5\n",
    "            t5+=1\n",
    "            if(val_groundtruth[i]+1) == np.argmax(prediction[i]):\n",
    "                t1+=1\n",
    "\n",
    "print('Size: 14MB')\n",
    "print('Peak memory usage is: {} KiB '.format(round(((tracemalloc.get_traced_memory()[1])/1024))))\n",
    "print('Top-1 accuracy for {} images is: {} %'.format(imagenum, round((t1/(imagenum))*100,1))) # Printing Accuracy.\n",
    "print('Top-5 accuracy for {} images is: {} %'.format(imagenum, round((t5/(imagenum))*100,1))) # Printing Accuracy.\n",
    "print('Latency is: {} s'.format(round(duration/(imagenum),2))) # Printing Latency.\n",
    "print('Throughput is: {} samples/sec'.format(round((imagenum)/duration,2))) # Printing Throughput.\n",
    "tracemalloc.stop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50 V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/tensorflow/resnet_50/classification/1\") # First input is the directory to the saved model.\n",
    "])\n",
    "model.build([batch, 224, 224, 3]) # Batch input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 98MB\n",
      "Peak memory usage is: 593280 KiB\n",
      "Top-1 accuracy for 1000 images is: 74.2 %\n",
      "Top-5 accuracy for 1000 images is: 91.6 %\n",
      "Latency is: 3.42 s\n",
      "Throughput is: 0.29 samples/sec\n"
     ]
    }
   ],
   "source": [
    "# Inference and metrics\n",
    "t1 = 0 # Variable for correct predictions\n",
    "t5 = 0 # Variable for top-5 correct predictions\n",
    "\n",
    "imagenum = 0\n",
    "data = np.zeros((1000 , 224, 224, 3))\n",
    "\n",
    "for file in os.listdir('Datasets/ImageNet')[:1000]:\n",
    "    image = Image.open(os.path.join('Datasets/ImageNet', file), 'r')\n",
    "    data[imagenum,:] = preprocessing(image, image_shape)[0] # Preprocessing\n",
    "    imagenum += 1\n",
    "\n",
    "tracemalloc.start()\n",
    "start = process_time()\n",
    "prediction = model.predict(data,batch_size = batch)\n",
    "duration += (process_time()-start)\n",
    "\n",
    "for i in range(imagenum):\n",
    "    if((val_groundtruth[i]) in np.argpartition(prediction[i], -5)[-5:]): # argpartition σε Ο(n) για τα top5\n",
    "        t5+=1\n",
    "        if(val_groundtruth[i]) == np.argmax(prediction[i]):\n",
    "            t1+=1\n",
    "\n",
    "print('Size: 98MB')\n",
    "print('Peak memory usage is: {} KiB'.format(round(((tracemalloc.get_traced_memory()[1])/1024))))\n",
    "print('Top-1 accuracy for {} images is: {} %'.format(imagenum, round((t1/(imagenum+1))*100,1))) # Printing Accuracy.\n",
    "print('Top-5 accuracy for {} images is: {} %'.format(imagenum, round((t5/(imagenum+1))*100,1))) # Printing Accuracy.\n",
    "print('Latency is: {} s'.format(round(duration/(imagenum),2))) # Printing Latency.\n",
    "print('Throughput is: {} samples/sec'.format(round((imagenum)/duration,2))) # Printing Throughput.\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/inception_v3/classification/5\") # First input is the directory to the saved model.\n",
    "])\n",
    "model.build([batch, 299, 299, 3]) # Batch input shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 92MB\n",
      "Peak memory usage is: 594512 KiB\n",
      "Top-1 accuracy for 1000 images is: 69.2 %\n",
      "Top-5 accuracy for 1000 images is: 87.5 %\n",
      "Latency is: 2.21 s\n",
      "Throughput is: 0.45 samples/sec\n"
     ]
    }
   ],
   "source": [
    "# Inference and metrics\n",
    "t1 = 0 # Variable for correct predictions\n",
    "t5 = 0 # Variable for top-5 correct predictions\n",
    "\n",
    "imagenum = 0\n",
    "duration = 0\n",
    "data = np.zeros((1000 , 224, 224, 3))\n",
    "\n",
    "for file in os.listdir('Datasets/ImageNet')[:1000]:\n",
    "    image = Image.open(os.path.join('Datasets/ImageNet', file), 'r')\n",
    "    data[imagenum,:] = preprocessing(image, image_shape)[0] # Preprocessing\n",
    "    imagenum += 1\n",
    "\n",
    "tracemalloc.start()   \n",
    "start = process_time()    \n",
    "prediction = model.predict(data,batch_size = batch)\n",
    "duration += (process_time()-start)\n",
    "\n",
    "for i in range(imagenum):\n",
    "    if((val_groundtruth[i]+1) in np.argpartition(prediction[i], -5)[-5:]): # argpartition σε Ο(n) για τα top5\n",
    "        t5+=1\n",
    "        if(val_groundtruth[i]+1) == np.argmax(prediction[i]):\n",
    "            t1+=1\n",
    "\n",
    "print('Size: 92MB')\n",
    "print('Peak memory usage is: {} KiB'.format(round(((tracemalloc.get_traced_memory()[1])/1024))))\n",
    "print('Top-1 accuracy for {} images is: {} %'.format(imagenum, round((t1/(imagenum))*100,1))) # Printing Accuracy.\n",
    "print('Top-5 accuracy for {} images is: {} %'.format(imagenum, round((t5/(imagenum))*100,1))) # Printing Accuracy.\n",
    "print('Latency is: {} s'.format(round(duration/(imagenum),2))) # Printing Latency.\n",
    "print('Throughput is: {} samples/sec'.format(round((imagenum)/duration,2))) # Printing Throughput.\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NASNet-A large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/nasnet_large/classification/5\")\n",
    "])\n",
    "model.build([batch, 331, 331, 3])  # Batch input shape.\n",
    "image_shape = (331,331)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 547.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 343MB\n",
      "Peak memory usage is: 135620 KiB\n",
      "Top-1 accuracy for 100 images is: 79.0 %\n",
      "Top-5 accuracy for 100 images is: 94.0 %\n",
      "Latency is: 21.82 s\n",
      "Throughput is: 0.05 samples/sec\n"
     ]
    }
   ],
   "source": [
    "# Inference and metrics\n",
    "t1 = 0 # Variable for correct predictions\n",
    "t5 = 0 # Variable for top-5 correct predictions\n",
    "\n",
    "imagenum = 0\n",
    "duration = 0\n",
    "data = np.zeros((100 , 331, 331, 3))\n",
    "\n",
    "for file in os.listdir('Datasets/ImageNet')[:100]:\n",
    "    image = Image.open(os.path.join('Datasets/ImageNet', file), 'r')\n",
    "    data[imagenum,:] = preprocessing(image, image_shape)[0] # Preprocessing\n",
    "    imagenum += 1\n",
    "\n",
    "tracemalloc.start()   \n",
    "start = process_time()    \n",
    "prediction = model.predict(data,batch_size = batch)\n",
    "duration += (process_time()-start)\n",
    "\n",
    "for i in tqdm(range(imagenum)):\n",
    "    if((val_groundtruth[i]+1) in np.argpartition(prediction[i], -5)[-5:]): # argpartition σε Ο(n) για τα top5\n",
    "            t5+=1\n",
    "            if(val_groundtruth[i]+1) == np.argmax(prediction[i]):\n",
    "                t1+=1\n",
    "\n",
    "print('Size: 343MB')\n",
    "print('Peak memory usage is: {} KiB'.format(round(((tracemalloc.get_traced_memory()[1])/1024))))\n",
    "print('Top-1 accuracy for {} images is: {} %'.format(imagenum, round((t1/(imagenum))*100,1))) # Printing Accuracy.\n",
    "print('Top-5 accuracy for {} images is: {} %'.format(imagenum, round((t5/(imagenum))*100,1))) # Printing Accuracy.\n",
    "print('Latency is: {} s'.format(round(duration/(imagenum),2))) # Printing Latency.\n",
    "print('Throughput is: {} samples/sec'.format(round((imagenum)/duration,2))) # Printing Throughput.\n",
    "tracemalloc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNetV2M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Model\n",
    "model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_m/classification/2\")\n",
    "])\n",
    "model.build([batch, 480, 480, 3])  # Batch input shape.\n",
    "image_shape = (480,480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 4833.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 220MB\n",
      "Peak memory usage is: 3515714 KiB\n",
      "Top-1 accuracy for 100 images is: 84.0 %\n",
      "Top-5 accuracy for 100 images is: 97.0 %\n",
      "Latency is: 23.45 s\n",
      "Throughput is: 0.04 samples/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Inference and metrics\n",
    "t1 = 0 # Variable for correct predictions\n",
    "t5 = 0 # Variable for top-5 correct predictions\n",
    "\n",
    "imagenum = 0\n",
    "duration = 0\n",
    "data = np.zeros((100 , 480, 480, 3))\n",
    "\n",
    "for file in os.listdir('Datasets/ImageNet')[:100]:\n",
    "    image = Image.open(os.path.join('Datasets/ImageNet', file), 'r')\n",
    "    data[imagenum,:] = preprocessing(image, image_shape)[0] # Preprocessing\n",
    "    imagenum += 1\n",
    "\n",
    "tracemalloc.start()   \n",
    "start = process_time()    \n",
    "prediction = model.predict(data,batch_size = batch)\n",
    "duration += (process_time()-start)\n",
    "\n",
    "for i in tqdm(range(imagenum)):\n",
    "    if((val_groundtruth[i]) in np.argpartition(prediction[i], -5)[-5:]): # argpartition σε Ο(n) για τα top5\n",
    "            t5+=1\n",
    "            if(val_groundtruth[i]) == np.argmax(prediction[i]):\n",
    "                t1+=1\n",
    "\n",
    "print('Size: 220MB')\n",
    "print('Peak memory usage is: {} KiB'.format(round(((tracemalloc.get_traced_memory()[1])/1024))))\n",
    "print('Top-1 accuracy for {} images is: {} %'.format(imagenum, round((t1/(imagenum))*100,1))) # Printing Accuracy.\n",
    "print('Top-5 accuracy for {} images is: {} %'.format(imagenum, round((t5/(imagenum))*100,1))) # Printing Accuracy.\n",
    "print('Latency is: {} s'.format(round(duration/(imagenum),2))) # Printing Latency.\n",
    "print('Throughput is: {} samples/sec'.format(round((imagenum)/duration,2))) # Printing Throughput.\n",
    "tracemalloc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('benchmarkapp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4bf7735f1ec2d00fd4695487ad6ad708baea5cbbc5c58424468c82ae75093a8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
